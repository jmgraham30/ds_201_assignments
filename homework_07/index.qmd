---
title: "DS 201 Homework 7"
format: 
  html:
    theme: pulse 
    toc: true 
    self-contained: true
---

```{r}
#| include: false

library(tidyverse)
library(tidymodels)
library(tidytext)
library(textrecipes)
library(themis)
library(tidylo)
library(ggthemes)

theme_set(theme_minimal(base_size = 13))

tidymodels_prefer()


```

This is Homework Assignment 7 for DS 201. You can view the source code for this assignment on GitHub: [view the source code](https://github.com/jmgraham30/ds_201_assignments/blob/main/homework_07/index.qmd).

For your amusement: Where do hamburgers like to dance? At a meatball!  


## Instructions

In this assignment, you will be working with the `tidymodels` package to train some basic supervised learning models[^1]. The data you will work with comes from the [TidyTuesday](https://github.com/rfordatascience/tidytuesday) data repository and has been discussed in the following blog posts by the data scientist Julia Silge:

- [Modeling human/computer interactions on Star Trek with workflowsets](https://juliasilge.com/blog/star-trek/).  For this data set, we will study a classification problem to predict whether an interaction is with a human or a computer. An interesting aspect to this problem is that out predictor variable is text data.

- [Modeling NCAA women's basketball tournament seeds](https://juliasilge.com/blog/ncaa-tuning/). For this data set, we will study a regression problem to predict the number of wins by a team. 

For one of these data sets has we will be interested in a numerical response variable and thus a regression problem, and for the other we will be interested in a categorical response variable and thus a classification problem. 

Here is what you will need to do:

1. Down load the Quarto notebook corresponding to this assignment from the course learning management system.

2. Make sure that you have all the necessary R packages installed. The code chunk at the top of the notebook loads all the packages you will need for this assignment. If you get an error message when you try to run this code chunk, make sure that you aren't missing any packages.

3. Go through the notebook and follow the provided prompts. In some cases, you will need to run a code chunk to produce output and then use the results to answer a question or respond to a prompt. In other cases, you will need to write code to produce an appropriate output.

[^1]: Refer to [lesson 8](https://intro-ds.netlify.app/lesson08/) from lecture for an overview of different models and model specifications. 


## Classification Problem for Human/Computer Interactions

We start by reading in the data:

```{r}
computer_raw <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-08-17/computer.csv")

computer_raw$char_type <- factor(computer_raw$char_type, levels = c("Person", "Computer"))

glimpse(computer_raw)
```

Examining this data set, we see that it contains a number of different variables. Our interest is to predict based on the words spoken by a character whether an interaction (predictor variable `interaction`) is with a human character or a computer (repose variable `char_type`). First note that of the interactions, 178 are with a computer and 234 are with a computer:

```{r}
computer_raw %>%
  distinct(value_id, .keep_all = TRUE) %>%
  count(char_type)
```

Before we proceed, we should will do some data exploration and look at which words are used by people and which are used by computers. 

```{r}
computer_counts <-
  computer_raw %>%
  distinct(value_id, .keep_all = TRUE) %>%
  unnest_tokens(word, interaction) %>%
  count(char_type, word, sort = TRUE)

computer_counts %>%
  bind_log_odds(char_type, word, n) %>%
  filter(n > 10) %>%
  group_by(char_type) %>%
  slice_max(log_odds_weighted, n = 10) %>%
  ungroup() %>%
  ggplot(aes(log_odds_weighted,
    fct_reorder(word, log_odds_weighted),
    fill = char_type
  )) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(vars(char_type), scales = "free_y") +
  labs(y = NULL)
```


**Exercise 1:** Run the previous code chunk which will produce a plot. Provide an interpretation of the plot. What are some words that are used commonly by humans and not computers? What are some words that are commonly used by computers and not humans?



The first step in the modeling process is to split the data into a training set and a testing set. We will use the training set to train our model and the testing set to evaluate the performance of our model. Run the following code chunk to split the data into a training set and a testing set:

```{r}
set.seed(123)

comp_split <-
  computer_raw %>%
  distinct(value_id, .keep_all = TRUE) %>%
  select(char_type, interaction) %>%
  initial_split(prop = 0.8, strata = char_type)

comp_train <- training(comp_split)
comp_test <- testing(comp_split)
```


The `distinct` function is to make sure that we keep only unique/distinct rows from our data. Now, we need to do some preprocessing of the data. The main goal of this is to make it so we can use text data. We will use functions from the `textrecipes` package to convert words to numerical values that can be used in a model. 

```{r}
rec_all <-
  recipe(char_type ~ interaction, data = comp_train) %>%
  step_tokenize(interaction) %>%
  step_tokenfilter(interaction, max_tokens = 80) %>%
  step_tfidf(interaction)

rec_all_norm <-
  rec_all %>%
  step_normalize(all_predictors())

rec_all_smote <-
  rec_all_norm %>%
  step_smote(char_type)

```

**Exercise 2:** Run the previous code chunk. Then, create a new code chunk and run the command `rec_all_smote %>% prep() %>% bake(comp_train)` to see what the data looks like after preprocessing. What do you notice about the data after preprocessing? 

Now, we will fit a model to the training data. Since the response variable is a binary categorical variable, we will fit a logistic regression model to the training data. To do so, we need to create an appropriate model specification. 

```{r}
log_reg_spec <- 
  logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

```

Now we create a workflow that will be used to fit the model. 

```{r}
log_reg_wf <-
  workflow() %>%
  add_recipe(rec_all_smote) %>%
  add_model(log_reg_spec)


```

**Exercise 3:** Run the previous code chunk. Then, create a new code chunk and run the command `log_reg_fit <- log_reg_wf %>% fit(comp_train)` to fit the model. 

With a fitted model, we can now make predictions on the testing data. 

**Exercise 4:** Create a new code chunk. In that chunk, copy, paste, and run the following code:

```
log_reg_fit %>%
  predict(comp_test, type="class") %>%
  bind_cols(comp_test) %>%
  conf_mat(truth = char_type, estimate = .pred_class)

```

What is the accuracy of the model on the testing data? 


**Exercise 5:** We can also make a plot of the confusion matrix computed in the previous exercise. Create a new code chunk and run the following code:

```
log_reg_fit %>%
  predict(comp_test, type="class") %>%
  bind_cols(comp_test) %>%
  conf_mat(truth = char_type, estimate = .pred_class) %>%
  autoplot()
```

What does this plot tell us about the performance of the model?

**Exercise 6:** Do you think that this model is a good model? Why or why not?


## Regression Problem for NCAA Women's Basketball Tournaments



